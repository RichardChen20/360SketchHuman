<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap" rel="stylesheet">
<script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
<link rel="stylesheet" type="text/css" href="./resources/style.css" media="screen" />
<link rel="icon" type="image/x-icon" href="./resources/ri-favicon.ico">

<html lang="en">

<head>
    <title>Sketch2Human3D</title>
    <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/
        if you update and want to force Facebook to re-scrape. -->
    <meta property="og:image" content="https://jasonyzhang.com/ners/resources/web_teaser.png" />
    <meta property="og:title"
        content="Sketch2Human3D: Transfer Your Sketch into Photo-Realistic 3D Human" />
    <meta property="og:description"
        content="Given in-the-wild multiview images, noisy cameras, and a rough shape initialization, we recover the shape deformation, texture, and illumination." />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-97476543-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'UA-97476543-1');
    </script>

</head>

<body>
    <div class="container">
        <div class="title">
            Sketch2Human3D: Transfer Your Sketch into Photo-Realistic 3D Human
        </div>

        <br>
        <br>

        <div class="author">
            <a href="https://sites.google.com/view/richardchen20">Ziwei Chen</a><sup>1</sup>
        </div>
        <div class="author">
            <a href="https://sites.google.com/view/richardchen20">Qiang Li</a><sup>2</sup>
        </div>
        <div class="author">
            <a href="https://sites.google.com/view/richardchen20">Jie Zhang</a><sup>3</sup>
        </div>
        <div class="author">
            <a href="https://sites.google.com/view/richardchen20">Tong-Yee Lee</a><sup>4</sup>
        </div>
        <div class="author">
            <a href="https://sites.google.com/view/richardchen20">Ping Li</a><sup>1*</sup>
        </div>

        <br>
        <br>

        <div class="affiliation"><sup>1</sup>The Hong Kong Polytechnic University</div>
        <div class="affiliation"><sup>2</sup>Sensetime Research</div>
        <div class="affiliation"><sup>3</sup>Macao Polytechnic University</div>
        <div class="affiliation"><sup>4</sup>National Cheng-Kung University</div>

        <br>
        <br>

        <!-- <div class="affiliation">ICLR 2023</div> -->
        <br>
        <br>

        <div class="links"><a href="https://github.com/RichardChen20/Sketch2Human3D">[Paper]</a></div>
        <div class="links"><a href="https://github.com/RichardChen20/Sketch2Human3D">[Video]</a></div>
        <div class="links"><a href="https://github.com/RichardChen20/Sketch2Human3D">[Code]</a></div>
        <!-- <div class="links"><a href="./paper_figures">[Figures]</a></div> -->
        <!-- <div class="links"><a href="https://drive.google.com/file/d/1hCKUx8pXctfDBXVKw32VTuX1Nb637BlD/view?usp=sharing">[Weights]</a></div> -->
        <br>
        <br>
        <div class="teaser-mid preview">
            <img style="width:100%;" src="./resources/images/show_img.png" alt="Results show figure" />
            <br>
            <i>
                Illustration of transferring 2D sketch to photo-realistic 3D human. Our Sketch2Human3D supports transferring hand-drawn sketches into 3D humans which can be rendered into multi-view RGB images and 3D shapes. For each hand-drawn sketch, we show two sets of images in different clothing styles and camera views.
            </i>
        </div>
        <!-- 
        <div class="teaser-right">
            <video autoplay loop muted playsinline width="100%">
                <source src="resources/videos/ners_wild_teaser.mp4" type="video/mp4">
            </video>
            <br>
            <i>
                We demonstrate the generality of NeRS on assorted objects.
            </i>
        </div> -->

        <br><br>

        <h1>Abstract</h1>
        <p>
            Creating photo-realistic 3D humans have wide applications in digital entertainment, online education and art design. 
            Existing works mainly employ coarse conditions such as pose to guide the generation, thus lacking detailed control over the synthesized results.
            To handle this issue, sketches can be a potential condition to achieve a more explicit and specific control.
            However, existing sketch-based generation methods are designed for 3D faces or rigid objects, how to transfer sketches into 3D humans remains unexplored.
            One straightforward idea is adapting sketch-based 3D face generation to human and another one is lifting sketch-based 2D human generation to 3D through a two-stage approach, however, both of them could lead to unsatisfactory degradation in 3D human generation quality.
            To fill the gap, in this work, we propose Sketch2Human3D, the first unified framework to achieve sketch-based 3D human generation, which is capable of synthesizing sketch-consistent and multi-view human images and corresponding human shapes simultaneously.
            Our unified framework guides the 3D human representation generation and rendering process by utilizing the geometry information extracted from the sketch.
            Specifically, we propose sketch-guided 3D representation generation to model the 3D human and maintain the consistency between input sketches and generated human images. 
            In addition, we equip the architecture of a typical 3D-aware GAN with spatial feature guidance and latent modulation provided by sketches to generate the 3D representation.
            Besides, our designed body-aware neural renderer leverages the 3D human body priors from sketches during the rendering process, reducing the difficulty of learning articulated body poses and complex body shapes.
            To train and evaluate our proposed Sketch2Human3D, we build a large-scale dataset containing around 39K 2D human images and their corresponding sketches in different styles.
            Experimental results show that our Sketch2Human3D can transfer different types of sketches into 3D full-body humans with high-quality rendering results and reasonable geometry. 
            We also demonstrate the effectiveness of our specific designs through ablation study and the feasibility of applying Sketch2Human3D to down-stream tasks.
        </p>

        <br><br>
        <hr>
        <h1>Overview</h1>
        <div class="teaser-mid preview">
            <img style="width:100%;" src="./resources/images/pipeline.png" alt="Model overview figure" />
            <br>
            <i>
                Illustration of sketch-based 3D full-body human generation. Our Sketch2Human3D supports transferring hand-drawn sketches into 3D humans which can be rendered into multi-view RGB images and 3D shapes. For each hand-drawn sketch, we show two sets of images in different clothing styles and camera views.
            </i>
        </div>
        
        <!-- <h1>Paper</h1>

        <div class="paper-thumbnail">
            <a href="https://openreview.net/pdf?id=WHlt5tLz12T">
                <img class="layered-paper-big" width="100%" src="./resources/images/liftedcl_paper.png"
                    alt="Paper thumbnail." />
            </a>
        </div>
        <div class="paper-info">
            <h4><a href="https://openreview.net/pdf?id=WHlt5tLz12T">LiftedCL: Lifting Contrastive Learning for Human-Centric Perception </a></h4>
            <h5>
                Ziwei Chen, Qiang Li, Xiaofeng Wang, and Wankou Yang
            </h5>
            <pre><code>@inproceedings{
                chen2023liftedcl,
                title={Lifted{CL}: Lifting Contrastive Learning for Human-Centric Perception},
                author={Ziwei Chen and Qiang Li and Xiaofeng Wang and Wankou Yang},
                booktitle={The Eleventh International Conference on Learning Representations },
                year={2023},
                url={https://openreview.net/forum?id=WHlt5tLz12T}
                }
            </code></pre>
        </div> -->

        <!-- <br><br>
        <hr><br> -->

        <!-- <h1>Video</h1>

        <div class="video-container">

            <iframe src="https://www.youtube.com/embed/zVyaw_sn1xM" title="YouTube video player" frameborder="0"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
        </div>
        <br><br>
        <hr> -->

        <!-- <h1>Code and Weights</h1>
        <a href="https://github.com/RichardChen20/LiftedCL">
            <img style="width:80%;" src="./resources/images/liftedcl_overall.png" alt="Model overview figure" />
        </a>
        <br>
        <a class="links" href="https://github.com/RichardChen20/LiftedCL">[GitHub]</a>
        <a class="links" href="https://drive.google.com/file/d/1hCKUx8pXctfDBXVKw32VTuX1Nb637BlD/view?usp=sharing">[Weights]</a>

        <br><br>
        <hr> -->
        
        <!--
        <h1>Data</h1>
        <div class="mesh-container">
            <div class="mesh">

                <model-viewer src="./resources/meshes/7246694387.glb" alt="A 3D model of a car" ar
                    ar-modes="webxr scene-viewer quick-look" environment-image="neutral" camera-orbit="0deg 75deg 105%"
                    auto-rotate camera-controls>
                </model-viewer>
            </div>
            <div class="mesh">

                <model-viewer src="./resources/meshes/espresso.glb" alt="A 3D model of an Espresso Machine" ar
                    ar-modes="webxr scene-viewer quick-look" environment-image="neutral"
                    camera-orbit="180deg 75deg 105%" auto-rotate camera-controls>
                </model-viewer>
            </div>
        </div>
        <br>

        <a class="links"
            href="https://drive.google.com/file/d/1P7BhDyUPhf4IF2FOWwddztYvjtIxR3II/view?usp=sharing">[Multi-view
            Marketplace Cars (on
            Google Drive)]</a>

        <br>
        Directions on how to download and use the data are on the <a
            href="https://github.com/jasonyzhang/ners#running-on-mvmc"> Github readme</a>.


        <br><br>
        <hr>

        <h1><a href="http://www.michaelhasey.com/deep-vernacular-summary">Reconstructing Ukrainian Churches</a></h1>
        <p>Check out <a href="http://www.michaelhasey.com/">Michael Hasey's</a> <a
                href="http://www.michaelhasey.com/deep-vernacular-summary">thesis</a>
            analyzing
            the architecture of Ukrainian
            churches by reconstructing over 300 NeRS models from online images!</p>
        <br>
        <div class="mesh-container">
            <div class="mesh">
                <img src="resources/churches/Church_of_St._Paraskevi.jpg" width="195.3px">
            </div>
            <div class="mesh">
                <video autoplay loop muted playsinline width="249.6px">
                    <source src="resources/churches/40_Church of St. Paraskevi.mp4" type="video/mp4">
                </video>
            </div>
        </div>
        <div class="mesh-container">
            <div class="mesh">
                <img src="resources/churches/Chuch_of_the_Transfer_of_the_Relics_of_St._Nicholas.jpg" width="220.8px">
            </div>
            <div class="mesh">
                <video autoplay loop muted playsinline width="241.9px">
                    <source src="resources/churches/95_Church of the Transfer of the Relics of St. Nicholas.mp4"
                        type="video/mp4">
                </video>
            </div>
        </div> -->
        <br><br>
        <!-- <hr> -->
        <h1>Acknowledgements</h1>
        <p>
            <!-- This work was supported by the National Natural Science Foundation of China under No. 62276061. -->
            <a href=" https://github.com/jasonyzhang/webpage-template">Webpage
                template</a>.
        </p>

        <br><br>
    </div>

</body>

</html>
